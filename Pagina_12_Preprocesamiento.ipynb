{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pagina_12_Preprocesamiento.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9bAjWawC5UH"
      },
      "source": [
        "# Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJJQDWrRC0Qj"
      },
      "source": [
        "# Instalacion de Bibliotecas\n",
        "!pip install gdown --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUizPRnBPe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee958b3-b574-4da3-b597-0b8fd19b0e0c"
      },
      "source": [
        "# Importo bibliotecas\n",
        "import gdown\n",
        "import sys\n",
        "import warnings\n",
        "import pprint\n",
        "import gc\n",
        "import pandas as pd\n",
        "import snowballstemmer\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# PrettyPrinter\n",
        "pp = pprint.PrettyPrinter(compact=True)\n",
        "pp = pprint.PrettyPrinter(indent=4, compact=True)\n",
        "\n",
        "# Libero memoria\n",
        "gc.collect()\n",
        "\n",
        "# No mostrar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Limite de recursion\n",
        "sys.setrecursionlimit(30000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oxdDp-zxCOY0",
        "outputId": "2fb72f37-49f1-4964-b0e5-6e080bf0a7e8"
      },
      "source": [
        "# Descargo datasets de secciones de noticias\n",
        "gdown.download('https://drive.google.com/uc?id=1qLM1mV45A9-hUI9dWb4SwtqCmfmAA35R', 'Sociedad.sav', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=19KLD-8nRba8XWwcw6YjChwB4KSZ10g6v', 'Economia.sav', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1juCpm4wAXHFXH3IBVQ3FrkfQ7I8r9BLn', 'ElMundo.sav', quiet=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qLM1mV45A9-hUI9dWb4SwtqCmfmAA35R\n",
            "To: /content/Sociedad.sav\n",
            "824MB [00:03, 212MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19KLD-8nRba8XWwcw6YjChwB4KSZ10g6v\n",
            "To: /content/Economia.sav\n",
            "839MB [00:18, 45.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1juCpm4wAXHFXH3IBVQ3FrkfQ7I8r9BLn\n",
            "To: /content/ElMundo.sav\n",
            "814MB [00:16, 48.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ElMundo.sav'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbH5o_0nDcMk"
      },
      "source": [
        "# Cargo secciones (Aproximadamente toma 5 minutos en cargar las tres secciones)\n",
        "society_section = joblib.load('Sociedad.sav')\n",
        "economy_section = joblib.load('Economia.sav')\n",
        "world_section = joblib.load('ElMundo.sav')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40TWBidjHG1n"
      },
      "source": [
        "# Concatenamos secciones\n",
        "news = pd.concat([society_section, economy_section, world_section], axis=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "yFBA6XWVci8j",
        "outputId": "66208f8d-793a-4d72-dc21-8c2254bf1aa9"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>date</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.pagina12.com.ar//370534-fue-a-cort...</td>\n",
              "      <td>\"Sin embargo, para sorpresa de la demandante (...</td>\n",
              "      <td>24 de septiembre de 2021 - 12:24</td>\n",
              "      <td>sociedad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.pagina12.com.ar//370530-lanzaron-u...</td>\n",
              "      <td>“El Plan fue presentado en varias jurisdiccion...</td>\n",
              "      <td>24 de septiembre de 2021 - 12:04</td>\n",
              "      <td>sociedad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.pagina12.com.ar//370527-orden-de-a...</td>\n",
              "      <td>El FBI pidió que cualquier persona que tenga i...</td>\n",
              "      <td>24 de septiembre de 2021 - 11:56</td>\n",
              "      <td>sociedad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.pagina12.com.ar//370567-julio-y-gi...</td>\n",
              "      <td>\"Esta muestra es un tributo con gran cariño de...</td>\n",
              "      <td>24 de septiembre de 2021 - 15:20</td>\n",
              "      <td>sociedad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.pagina12.com.ar//370349-yemen-un-g...</td>\n",
              "      <td>La investigación se abocó al primer descenso d...</td>\n",
              "      <td>24 de septiembre de 2021 - 01:34</td>\n",
              "      <td>sociedad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...     topic\n",
              "0  https://www.pagina12.com.ar//370534-fue-a-cort...  ...  sociedad\n",
              "1  https://www.pagina12.com.ar//370530-lanzaron-u...  ...  sociedad\n",
              "2  https://www.pagina12.com.ar//370527-orden-de-a...  ...  sociedad\n",
              "3  https://www.pagina12.com.ar//370567-julio-y-gi...  ...  sociedad\n",
              "4  https://www.pagina12.com.ar//370349-yemen-un-g...  ...  sociedad\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21yHygRIHH3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc17ebf-e7d7-4c68-d6e5-35016238fb9a"
      },
      "source": [
        "# Borramos temporal de secciones\n",
        "del society_section\n",
        "del economy_section\n",
        "del world_section\n",
        "\n",
        "# Libero memoria\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6804536"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFQu0839D9Bu"
      },
      "source": [
        "# Stopwords\n",
        "stopwords_es = pd.read_csv('https://drive.google.com/uc?export=download&id=1prdR9zCvSQnEIZoLf5B0TiS1tUhMLClC', header = None)\n",
        "stopwords_es_sin_acentos = pd.read_csv('https://drive.google.com/uc?export=download&id=1QDLZXPDnJ1XbHJRukDgqxi5P0AKtssd_', header = None)\n",
        "\n",
        "stopwords = pd.concat([stopwords_es, stopwords_es_sin_acentos])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDOJHqMiEc5T"
      },
      "source": [
        "def remove_stop_words(text):\n",
        "  \"\"\"\n",
        "    Remueve stop words en inglés\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    text: list\n",
        "      lista de palabras (tokens) a filtrar\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "      lista de palabras sin los stop words\n",
        "  \"\"\"\n",
        "  return [token for token in text if token.lower() not in stopwords]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkkzUGExEdRy"
      },
      "source": [
        "def tokenize(text): \n",
        "  \"\"\"\n",
        "  :param text: Una expresion regular que define que es un token\n",
        "  :return: Una funcion que recibe un texto y retorna el texto tokenizado.\n",
        "  \"\"\"\n",
        "  if text is None:\n",
        "    text = r\"[a-zA-ZâáàãõáêéíóôõúüÁÉÍÓÚñÑçÇ][0-9a-zA-ZâáàãõáêéíóôõúüÁÉÍÓÚñÑçÇ]+\"\n",
        "  token_pattern = re.compile(text)\n",
        "  return lambda doc: token_pattern.findall(doc)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIxt6J9MEdVu"
      },
      "source": [
        "stemmer = snowballstemmer.stemmer(\"spanish\")\n",
        "\n",
        "def stem_words(tokens):\n",
        "    \"\"\"\n",
        "    Transforma mediante un stemmer a una secuencia de tokens.\n",
        "    :param tokens: Una secuencia de tokens.\n",
        "    :return La secuencia de tokens transformada por el stemmer.\n",
        "    \"\"\"\n",
        "    global stemmer\n",
        "    return [stemmer.stem(word) for word in tokens]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtSPecIoEdYB"
      },
      "source": [
        "def clean_short_words(text):\n",
        "  \"\"\"\n",
        "    Limpia palabras con longitud 1\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    text: str\n",
        "      documento a tokenizar\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "      lista de tokens\n",
        "  \"\"\"\n",
        "  return [word for word in text if len(word) > 1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk0af5VZEdaf"
      },
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "  \"\"\"\n",
        "    Pre-procesamiento\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    text: str\n",
        "      documento a analizar\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "      retorna un dataframe con las 20 palabras que más se repiten y su frecuencia\n",
        "  \"\"\"\n",
        "  tokenized = tokenize(text)\n",
        "  without_stops = remove_stop_words(tokenized)\n",
        "  without_short_words = clean_short_words(without_stops)\n",
        "  stemmed_words = stem_words(without_short_words)\n",
        "  return stemmed_words"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVysaHReEdcw"
      },
      "source": [
        "# cantidad minima de docs que tienen que tener a un token para conservarlo.\n",
        "MIN_DF=3\n",
        "# cantidad maxima de docs que tienen que tener a un token para conservarlo.\n",
        "MAX_DF=0.8\n",
        "# numero minimo tokens consecutivos que se consideran\n",
        "MIN_NGRAMS=1\n",
        "# numero maximo tokens consecutivos que se consideran\n",
        "MAX_NGRAMS=2\n",
        "\n",
        "# aplicamos count vectorizer\n",
        "vectorizer = CountVectorizer(tokenizer=preprocess_text,\n",
        "                                 lowercase=True, strip_accents='unicode', decode_error='ignore',\n",
        "                                 ngram_range=(MIN_NGRAMS, MAX_NGRAMS), min_df=MIN_DF, max_df=MAX_DF)\n",
        "\n",
        "#vectorizer.fit_transform(DATASETFALOPA)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsvNtvl_fMuh"
      },
      "source": [
        "## Acá empezaría el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KwLCbtPdflY"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgt8WMrHdomD"
      },
      "source": [
        "# pasar categorias a numeros (1ra categoria = 0, 2da categoria = 1, etc)\n",
        "label_encoder = LabelEncoder()\n",
        "targets = label_encoder.fit_transform(news.topic)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HaTibAAeQxH"
      },
      "source": [
        "# idx_a_clase es un diccionario indice de categoria -> nombre de categoria\n",
        "idx_a_clase = label_encoder.classes_"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHLL_E2XeICB"
      },
      "source": [
        "# cantidad de categorias distintas que tenemos en el conj. de entrenamiento\n",
        "n_categorias = len(idx_a_clase)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryxIK1iHfYud"
      },
      "source": [
        "# el clasificador que vamos a usar\n",
        "clasificador = SVC(kernel='linear', probability=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-sjq-Tfbap"
      },
      "source": [
        "# cantidad maxima de features que seleccionara el extractor de features\n",
        "MAX_FEATURES=150\n",
        "# cantida de folds a usar en cross-val\n",
        "CANT_FOLDS_CV=5"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHAD4X7adQN0"
      },
      "source": [
        "# transformar los targets en N columnas, 1 por cada categoria, donde la categoria correcta tiene un 1 y todas las demas columnas en esa fila tienen 0.\n",
        "# Dado que AUC se calcula sobre 2 categorias, Usamos esto luego para calcular 1 AUC por cada categoria\n",
        "targets_binarios_por_clase = label_binarize(targets, classes=range(0, n_categorias))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW-rvd6WezM4"
      },
      "source": [
        "# hacer cross-validation\n",
        "n_fold = 1\n",
        "accuracy_promedio = 0"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}